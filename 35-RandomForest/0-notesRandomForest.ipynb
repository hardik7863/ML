{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we use bagging and boosting ensemble techniques which uses multiple techniques like decision tree ,logistic tree ,naive bayes ,etc this are called base learners\n",
    "\n",
    "\n",
    "to find best solution ---this is used for kaggle competetions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random forest is one of the ensemble technique \n",
    "\n",
    "in a given data set we use 100s of base learners and provide them different samples of dataset after training the model we give the test data\n",
    "\n",
    "then majority voting classifier is used for the final output i.e if majority is giving 0 then final output will be 0 in case of classification problem\n",
    "\n",
    "whereas in case of regression problem we take the average of all output of base learners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All base learners are train parallelly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea behind boosting\n",
    "we have dataset we use all weak learners sequentially to get strong learner\n",
    "\n",
    "model1 will get the complete dataset then it will have some accuracy then this will pass the records which are wrong predicted to the next model then this model will send its wrong records to the next model this process will happen sequentially till n model\n",
    "lets say there are 5 models each of them is train for 5 different subjects this will give better accuracy at the end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random forest classification and regression is the example of the bagging and boosting ensemble technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d is the size of dataset f1 f2 fn are the features\n",
    "In random forest, we have the all base learners as Decision trees\n",
    "\n",
    "\n",
    "Why Should we use Random forest instead of decision tree using random forest will have high time complexity?\n",
    "Decision tree often led to overfitting which mean train accuracy is high i.e low bias and test accuracy is low i.e high variance \n",
    "we use generalize model in random forest which have low bias and low variance  \n",
    "time complexity may be high but the accuracy is good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
