{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **SVM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be used for solving both classification problem and regression problem\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) SVC (Support vector Classifer)\n",
    "2) SVR (Support Vector Regressor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **CORE Concept of SVM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In SVM,we are trying to create a best fit line in case of 2 d plane we need to create two marginal plane which are equidistance from the best fit line such that the distance between two marginal plane should be maximum "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the points through which marginal plane passes are called support vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **SOft Margin and Hard Margin**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you are clearly separting points and there is no error (due to overlapping of points error may occur) is called hard margin\n",
    "\n",
    "but when you are not able to separate the points and there are errors (due to overlapping of points error may occur) then it is called soft margin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **MAth Intution of SVC**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have seen earlier,\n",
    "ax+by+c=0    =>  w1x1 + w2x2 + b =0   => wT(w transpose)x +b =0 \n",
    "\n",
    "if b=0 i.e line passes through origin \n",
    "then wTx=0\n",
    "\n",
    "here w is the vector perpendicular to the line \n",
    "\n",
    "Since the angle btw w and S is greator than 90 degree then points lie below the line will have negative distance \n",
    "\n",
    "Since the angle btw w and s' is btw 0 to 90 degree then points lie above the line will have Positive distance\n",
    "\n",
    "then d'>d \n",
    "\n",
    "the marginal plane with positive distance can be given as wTx + b = +1\n",
    "\n",
    "whereas the marginal plane with negative distance can be given as wTx +b=-1\n",
    "\n",
    "on solving this two equation we will divide both the side with magnitude of W and we will get unit vector \n",
    "\n",
    "wT(x1-x2)=  2\n",
    "\n",
    "on dividing with ||W|| on both side \n",
    "\n",
    "we get unit vector = 2/||W|| which is our cost function\n",
    " \n",
    "\n",
    " 2/||W|| is the distance btw the marginal plane\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer the lecture notes\n",
    "\n",
    "In cost function of SVC we are trying to maximize (2/||w||) \n",
    "\n",
    "here ||w|| is the magnitude of perpendicular vector on best fit line \n",
    "\n",
    "by changing the values of w,b\n",
    "\n",
    "or we can say minimize (||w||/2) by changing w,b\n",
    "\n",
    "if we go through to the constraint we will get \n",
    "\n",
    "yi * (wTx+b) >=1 always for all correct points\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Fine Tuning of SVC**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cost function of SVC = min ||w||/2 + Ci summation from i=1 to n ETTAi\n",
    "\n",
    "here Ci is the hyperparameter i.e how many points we want to avoid for misclassification\n",
    "lets say there are 7 points overlapping out of 100 points then if ci is 8 then we can avoid the 7 error points  and consider the marginal planes \n",
    "\n",
    "ETTAi is the summation of the distance of the incorrect data points from the marginal plane \n",
    "\n",
    "Ci summation from i=1 to n ETTAi is called hinge Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **SVR**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In SVR, the cost function of SVR = minimize ||w||/2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **SVR Kernels**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Svc cannot be used when the datapoints are forming concurrent circle or any shape in which linear SvC in not applicable then we will use SVC kernels it uses the tranfomation techniques(mathematical formula) to convert the dataset in 2d into 3d so that SVR can be applied more efficiently and get the high accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Different SVR Kernels**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
